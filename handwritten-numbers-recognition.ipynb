{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MNIST database has a training set of 60000 examples.\n",
      "The MNIST database has a test set of 10000 examples.\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"The MNIST database has a training set of %d examples.\" % len(X_train))\n",
    "print(\"The MNIST database has a test set of %d examples.\" % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADBCAYAAABIbSwnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4gAAAADUgCEOAAAAQA0Y4gAAAADUwP8Fc1l4oyGRvWAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x1440 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(1, 6, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rescale [0,255] --> [0,1]\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer-valued labels:\n",
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "One-hot labels:\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# print first ten (integer-valued) training labels\n",
    "print('Integer-valued labels:')\n",
    "print(y_train[:10])\n",
    "\n",
    "# one-hot encode the labels\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# print first ten (one-hot) training labels\n",
    "print('One-hot labels:')\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 9s 178us/step - loss: 0.2741 - acc: 0.9154 - val_loss: 0.1154 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11540, saving model to mnist.model.best.hdf5\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.1111 - acc: 0.9665 - val_loss: 0.0955 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11540 to 0.09547, saving model to mnist.model.best.hdf5\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 8s 156us/step - loss: 0.0793 - acc: 0.9763 - val_loss: 0.0827 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09547 to 0.08268, saving model to mnist.model.best.hdf5\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 8s 169us/step - loss: 0.0626 - acc: 0.9804 - val_loss: 0.0869 - val_acc: 0.9754\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08268\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 8s 167us/step - loss: 0.0511 - acc: 0.9843 - val_loss: 0.0845 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08268\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 8s 165us/step - loss: 0.0428 - acc: 0.9868 - val_loss: 0.0905 - val_acc: 0.9795\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08268\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.0403 - acc: 0.9882 - val_loss: 0.0935 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08268\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.0316 - acc: 0.9902 - val_loss: 0.0987 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08268\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.0293 - acc: 0.9907 - val_loss: 0.1152 - val_acc: 0.9772\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08268\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 8s 163us/step - loss: 0.0257 - acc: 0.9919 - val_loss: 0.1108 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08268\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='number-recognition.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('number-recognition.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 98.5600%\n"
     ]
    }
   ],
   "source": [
    "# evaluate training accuracy\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print training accuracy\n",
    "print('Training accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.7700%\n"
     ]
    }
   ],
   "source": [
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nnseries]",
   "language": "python",
   "name": "conda-env-nnseries-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
